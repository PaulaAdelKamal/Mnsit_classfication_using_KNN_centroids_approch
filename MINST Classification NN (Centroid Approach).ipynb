{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST Classification KNN (Centroid Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this notebook will use MINST dataset of handwritten digIts from one to 9 \n",
    "- we will use only 10000 data-point for training and 1000 data-point for test as asked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essintial imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\paula\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from itertools import product\n",
    "from IPython.display import display, clear_output\n",
    "from itertools import combinations ,combinations_with_replacement\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, OrderedDict\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing preprocessed data from keras  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11493376/11490434 [==============================] - 13s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist \n",
    "(xtrain , y_train) , (xtest,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (60000, 28, 28) (60000,)\n",
      "Test samples: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples:\", xtrain.shape, y_train.shape)\n",
    "print(\"Test samples:\", xtest.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xtrain.reshape(xtrain.shape[0], 1, 28*28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### taking small portion as asked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=xtrain[50000:]\n",
    "y_train=y_train[50000:]\n",
    "xtest=xtest[9000:]\n",
    "y_test=y_test[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: (10000, 28, 28) (10000,)\n",
      "Test samples: (1000, 28, 28) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train samples:\", xtrain.shape, y_train.shape)\n",
    "print(\"Test samples:\", xtest.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plotting digits in grey scale just for illustration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "6\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "9\n",
      "5\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = 5\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols , 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, 1000)\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(xtrain[random_index, :] ,cmap='gray')\n",
    "        print(y_train[random_index])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imaged_grid is function that slice the photo into certain amount of grids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imaged_grid(img , row , col ):\n",
    "    x , y = img.shape\n",
    "    return (img.reshape ( x //row, row, -1, col).swapaxes(1,2).reshape(-1, row, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 14, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,  17,  80, 104, 255, 242,  49,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,  53, 253, 253, 253, 253, 156,   0,   0,\n",
       "           0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   1],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          44, 111],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         111, 253]],\n",
       "\n",
       "       [[  0,   0,   0,  37, 223, 253, 253, 253, 248, 119,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,  40, 207, 253, 253, 253, 253, 137,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,  30, 224, 253, 253, 253, 253, 233,  50,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 43, 208, 253, 253, 253, 253, 236,  72,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [106, 253, 253, 253, 253, 239,  74,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [253, 253, 253, 253, 231,  71,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [253, 253, 253, 248,  72,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  88,\n",
       "         253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  82, 235,\n",
       "         253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  13, 159, 253,\n",
       "         253, 253],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  84, 167, 253, 253,\n",
       "         253, 248],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 140, 253, 253, 253,\n",
       "         253, 207],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 140, 253, 253, 253,\n",
       "         198,  33],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 197, 234, 253, 253, 231,\n",
       "          25,   0]],\n",
       "\n",
       "       [[253, 253, 228,  68,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [253, 253, 182,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [228,  67,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [ 68,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0, 237, 253, 253, 197, 125,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   6, 128, 249, 253, 250, 122,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,  80, 253, 253, 253, 142,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,  25, 187, 253, 253,  34,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(2  , 2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "#ax.imshow(xtest[8] ,cmap='gray')\n",
    "print(imaged_grid(xtest[4] , 14 , 7 ).shape)\n",
    "imaged_grid(xtest[5] , 7 , 14 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### Get the centroid (centet of mass of grey scale) of each slice (grid) made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(img ,L):\n",
    "    feature = []\n",
    "    for grid in imaged_grid(img , L[0] , L[1] ) :\n",
    "        X = 0 \n",
    "        Y = 0 \n",
    "        s = 0\n",
    "        for index, bit in np.ndenumerate(grid):\n",
    "          s+= bit\n",
    "          X += bit * index[0]\n",
    "          Y += bit * index[1]  \n",
    "        if s != 0 :\n",
    "            feature.append( X/ s )\n",
    "            feature.append(Y/ s )\n",
    "        else :\n",
    "             feature.append(0)\n",
    "             feature.append(0)\n",
    "    return np.array(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### extracting train and test features using previous funcution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feature size =>(10000, 16)\n",
      "test feature size =>(1000, 16)\n"
     ]
    }
   ],
   "source": [
    "l = [14,7]\n",
    "trainf = [get_centroid(img,l)  for img in xtrain ]\n",
    "trainf = np.array (trainf)\n",
    "print (f'train feature size =>{trainf.shape}')\n",
    "testf = [get_centroid(img,l)  for img in xtest]\n",
    "testf = np.array (testf)\n",
    "print(f'test feature size =>{testf.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([11.5       ,  6.        ,  9.27056884,  3.00263809, 10.44494382,\n",
       "        3.57512039, 10.06481481,  0.97074074, 11.08      ,  6.        ,\n",
       "        8.71985583,  3.02604849,  2.50737207,  1.75390286,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (trainf[0].shape , testf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting feature using KNeighborsClassifier using ecludian distance then predict using Accuracy metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(3 , metric = 'euclidean')\n",
    "model.fit (trainf , y_train)\n",
    "ypred = model.predict(testf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy=\", accuracy_score(y_test, ypred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impleminting NN from scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get batch from the training set.\n",
    "* Pass batch to network(we will build).\n",
    "* Calculate the loss (difference between the predicted values and the true values).\n",
    "* Calculate the gradient of the loss function w.r.t the network's weights (backward propagation).\n",
    "* Update the weights using the gradients to reduce the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- We feed input data into the neural network\n",
    "-- The data flows from layer to layer until we have the output.\n",
    "\n",
    "--Once we have the output, we can calculate the error which is a scalar.\n",
    "\n",
    "-- Finally we can adjust a given parameter (weight or bias) by subtracting the derivative of the error with respect to the parameter itself.\n",
    "\n",
    "--We iterate through that process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense layer - a fully-connected layer, $f(X)=W \\cdot X + \\vec{b}$\n",
    "- ReLU layer (or any other nonlinearity you want)\n",
    "- Loss function - crossentropy\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    \"\"\"\n",
    "        Performs a backpropagation step through the layer, with respect to the given input.\n",
    "        \n",
    "        To compute loss gradients w.r.t input, you need to apply chain rule (backprop):\n",
    "        \n",
    "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
    "        \n",
    "        Luckily, you already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
    "        \n",
    "        If your layer has parameters (e.g. dense layer), you also need to update them here using d loss / d layer\n",
    "        \"\"\"\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(input):\n",
    "    return np.maximum (0,input)\n",
    "    \n",
    "def Relubackword ( input ,grad_output):\n",
    "    relu_grad = input > 0\n",
    "    return relu_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\EGYPT\\\\Pictures\\\\Screenshots\\\\Screenshot (866).png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0d026620d0b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\EGYPT\\\\Pictures\\\\Screenshots\\\\Screenshot (866).png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[1;32m-> 1204\u001b[1;33m                 metadata=metadata)\n\u001b[0m\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\EGYPT\\\\Pictures\\\\Screenshots\\\\Screenshot (866).png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "#PATH = \"C:\\\\Users\\\\EGYPT\\\\Pictures\\\\Screenshots\\\\Screenshot (866).png\"\n",
    "#Image(filename = PATH , width=1000, height=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        #Random initialization of weights for each layer [1]\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        #Multiplying weights with the input of each layer to get the output [1]\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        \n",
    "        #Saving the output of each layer to use it here in backpropagation [1]\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    #the derivative of the error with respect to that layer’s output (∂E/∂Y)\n",
    "    #The derivative of the error with respect to the parameters (∂E/∂W, ∂E/∂B)\n",
    "    #The derivative of the error with respect to the input (∂E/∂X)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        #∂E/∂X = ∂E/∂Y * W.T\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        \n",
    "        #∂E/∂W = x.T * ∂E/∂Y\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error\n",
    "\n",
    "        # update parameters\n",
    "        #Backward the error and calculating the update to the weights for the All layer [0.75] (easy) [1.25] (hard)\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        #output_error =dE/dY\n",
    "        #∂E/∂x =   dE/dY * activition drevitive \n",
    "        return self.activation_prime(self.input) * output_error\n",
    "    \n",
    "    \n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x))\n",
    "    return z;\n",
    "\n",
    "def sigmoidDrivitve(x):\n",
    "    z = 1 / (1 + np.exp(-x)) * (1 - (1 / (1 + np.exp(-x))))\n",
    "    return z;\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.sum(np.power(y_true-y_pred, 2))/y_true.shape[0];\n",
    "\"\"\"error = [(p - o) for p, o in zip(y_pred, y_true)]\n",
    "    square_error = [e**2 for e in error]\n",
    "    mean_square_error = sum(square_error)/len(square_error)\n",
    "    return min(mean_square_error)\"\"\"\n",
    "\n",
    "\n",
    "#Calculate the derivative of the MSE error [1]\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    \n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "   \n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        for i in range(samples):\n",
    "           \n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "  \n",
    "        samples = len(x_train)\n",
    "\n",
    "       \n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                \n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                err += self.loss(y_train[j], output)\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            err /= samples\n",
    "            print(f'epoch {i+1}   error= {err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapping all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "  \n",
    "  y = np.array(y, dtype='int')\n",
    "  input_shape = y.shape\n",
    "  if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "    input_shape = tuple(input_shape[:-1])\n",
    "  y = y.ravel()\n",
    "  if not num_classes:\n",
    "    num_classes = np.max(y) + 1\n",
    "  n = y.shape[0]\n",
    "  categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "  categorical[np.arange(n), y] = 1\n",
    "  output_shape = input_shape + (num_classes,)\n",
    "  categorical = np.reshape(categorical, output_shape)\n",
    "  return categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (y_train.shape ,y_test .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tr = trainf.reshape(trainf.shape[0], 1, 28*28)\\ntr.shape'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (trainf.shape)\n",
    "\n",
    "\"\"\"tr = trainf.reshape(trainf.shape[0], 1, 28*28)\n",
    "tr.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "#At least 2 layers (hidden layer + output layer) [0.5]\n",
    "#Number of neurons can be changed, and minimum neurons should be 4 (both for this grade) [1]\n",
    "net.add(Dense(16 , 100))              \n",
    "net.add(ActivationLayer(sigmoid, sigmoidDrivitve))\n",
    "net.add(Dense(100, 50))                  \n",
    "net.add(ActivationLayer(sigmoid, sigmoidDrivitve))\n",
    "net.add(Dense(50, 10))\n",
    "#Activation function (sigmoid) for the last layer [0.5]\n",
    "net.add(ActivationLayer(sigmoid, sigmoidDrivitve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainff = trainf.reshape(trainf.shape[0], 1, 8*2)\n",
    "display ( trainff . shape, trainf . shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train . shape\n",
    "y_trainn = y_train.reshape(y_train.shape[0], 1, 10)\n",
    "display ( y_train . shape, y_train . shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1   error= 0.0818430472646947\n",
      "epoch 2   error= 0.05898024514796989\n",
      "epoch 3   error= 0.04811941106331205\n",
      "epoch 4   error= 0.04262237780632218\n",
      "epoch 5   error= 0.03874070826595906\n",
      "epoch 6   error= 0.03566315281869009\n",
      "epoch 7   error= 0.033168682405116806\n",
      "epoch 8   error= 0.03115770432074519\n",
      "epoch 9   error= 0.02953719570091871\n",
      "epoch 10   error= 0.028244340353185505\n",
      "epoch 11   error= 0.027198539979734204\n",
      "epoch 12   error= 0.026336294779942322\n",
      "epoch 13   error= 0.02561866348937928\n",
      "epoch 14   error= 0.025017740771147066\n",
      "epoch 15   error= 0.0245056534297389\n",
      "epoch 16   error= 0.024060133622226944\n",
      "epoch 17   error= 0.023665806642320673\n",
      "epoch 18   error= 0.02331156413598243\n",
      "epoch 19   error= 0.022988920808802698\n",
      "epoch 20   error= 0.02269127233887582\n",
      "epoch 21   error= 0.022413668340931666\n",
      "epoch 22   error= 0.022152580627295443\n",
      "epoch 23   error= 0.02190544913967608\n",
      "epoch 24   error= 0.021670274426931327\n",
      "epoch 25   error= 0.02144557264849439\n",
      "epoch 26   error= 0.02123042705255851\n",
      "epoch 27   error= 0.02102423050190489\n",
      "epoch 28   error= 0.02082647579590672\n",
      "epoch 29   error= 0.02063672974307206\n",
      "epoch 30   error= 0.020454526701907224\n",
      "epoch 31   error= 0.020279290465821644\n",
      "epoch 32   error= 0.02011045519253394\n",
      "epoch 33   error= 0.019947668840766375\n",
      "epoch 34   error= 0.01979078008185389\n",
      "epoch 35   error= 0.0196396392167364\n",
      "epoch 36   error= 0.019493975834036146\n",
      "epoch 37   error= 0.01935338320196305\n",
      "epoch 38   error= 0.01921737466994027\n",
      "epoch 39   error= 0.019085408015942686\n",
      "epoch 40   error= 0.018955323299816605\n",
      "epoch 41   error= 0.01882104381303577\n",
      "epoch 42   error= 0.01868979939145323\n",
      "epoch 43   error= 0.01856463099903162\n",
      "epoch 44   error= 0.01844470562152974\n",
      "epoch 45   error= 0.01832933857578151\n",
      "epoch 46   error= 0.01821799525655638\n",
      "epoch 47   error= 0.01811022105517646\n",
      "epoch 48   error= 0.01800559934418389\n",
      "epoch 49   error= 0.017903729776515324\n",
      "epoch 50   error= 0.017804222044642704\n",
      "epoch 51   error= 0.017706729711199517\n",
      "epoch 52   error= 0.01761103000983975\n",
      "epoch 53   error= 0.017517059620965985\n",
      "epoch 54   error= 0.017424826792183507\n",
      "epoch 55   error= 0.017334318179100704\n",
      "epoch 56   error= 0.017245506496433853\n",
      "epoch 57   error= 0.017158385223118446\n",
      "epoch 58   error= 0.017072954537654346\n",
      "epoch 59   error= 0.01698918190375524\n",
      "epoch 60   error= 0.01690699878468478\n",
      "epoch 61   error= 0.01682633803765397\n",
      "epoch 62   error= 0.016747178875778975\n",
      "epoch 63   error= 0.016669554882638108\n",
      "epoch 64   error= 0.016593474021820195\n",
      "epoch 65   error= 0.016518821942161404\n",
      "epoch 66   error= 0.016445419057186973\n",
      "epoch 67   error= 0.01637314262663826\n",
      "epoch 68   error= 0.01630195406612661\n",
      "epoch 69   error= 0.016231844152906908\n",
      "epoch 70   error= 0.016162787722640036\n",
      "epoch 71   error= 0.01609473544005623\n",
      "epoch 72   error= 0.016027613239847804\n",
      "epoch 73   error= 0.01596138625980597\n",
      "epoch 74   error= 0.015896165428672372\n",
      "epoch 75   error= 0.015831869546994247\n",
      "epoch 76   error= 0.015767883979338388\n",
      "epoch 77   error= 0.015704326691665223\n",
      "epoch 78   error= 0.01564171832022923\n",
      "epoch 79   error= 0.015580297678624075\n",
      "epoch 80   error= 0.015520092071277407\n",
      "epoch 81   error= 0.015461031287736302\n",
      "epoch 82   error= 0.015402999995861774\n",
      "epoch 83   error= 0.015345867870838692\n",
      "epoch 84   error= 0.015289509805036983\n",
      "epoch 85   error= 0.015233817335362831\n",
      "epoch 86   error= 0.015178703292567812\n",
      "epoch 87   error= 0.015124098743847535\n",
      "epoch 88   error= 0.015069939616381908\n",
      "epoch 89   error= 0.015016158614066398\n",
      "epoch 90   error= 0.014962709194896376\n",
      "epoch 91   error= 0.014909609143123543\n",
      "epoch 92   error= 0.014856962298303493\n",
      "epoch 93   error= 0.01480491726938136\n",
      "epoch 94   error= 0.01475360394770951\n",
      "epoch 95   error= 0.014703114227868835\n",
      "epoch 96   error= 0.01465350840232282\n",
      "epoch 97   error= 0.014604816426753299\n",
      "epoch 98   error= 0.014557034819482607\n",
      "epoch 99   error= 0.014510126234186174\n",
      "epoch 100   error= 0.01446402370540421\n"
     ]
    }
   ],
   "source": [
    "net.use(mse, mse_prime)\n",
    "net.fit(trainff[0:10000], y_train[0:10000], epochs=100, learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = 0\n",
    "#Transforming output vector into a label [0.5]\n",
    "out = net.predict(testf[0:1000])\n",
    "for i in range (len(out)):\n",
    "    \n",
    "    l = max(out[i][0])\n",
    "    max_index = np.where(out[i][0] == l)\n",
    "    pred = max_index [0][0]\n",
    "    \n",
    "    max_index_test = np.where(y_test[i] == 1)\n",
    "    max_index_test[0] [0]\n",
    "    \n",
    "    \n",
    "    #Comparing and getting the % [0.5]\n",
    "    if (pred == max_index_test):summ+=1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is 855 correct sample out of 1000 sample\n",
      "Accurcy = 85.5 %\n"
     ]
    }
   ],
   "source": [
    "Acc = (summ / len(out)) * 100\n",
    "#Comparing and getting the % [0.5]\n",
    "print (f\"there is {summ} correct sample out of {len(out)} sample\")\n",
    "print (f\"Accurcy = {Acc} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
